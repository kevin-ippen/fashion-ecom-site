# Notebook Inventory & Organization

> Analysis of which notebooks are actively used vs. exploratory research

## ğŸ¯ Production Notebooks (Used)

These notebooks implement the **Pattern-Based Outfit Pairing** system currently in production:

### Core Pipeline (Executed in Order)
1. **01_select_anchor_products.py** â†’ Selects ~200 representative anchor products using stratified sampling
   - Input: All products from `main.fashion_sota.products_lakebase`
   - Output: `data/anchor_products.json` (72KB)
   - Status: âœ… Completed

2. **02_generate_outfit_patterns.py** â†’ Generates 5-10 reusable patterns per anchor using GenAI
   - Input: `data/anchor_products.json`
   - Output: `data/outfit_patterns.json` (153KB)
   - Status: âœ… Completed

3. **04_batch_apply_patterns.py** â†’ Applies patterns to all products via similarity matching
   - Input: `data/outfit_patterns.json` + product catalog
   - Output: `data/pattern_based_recommendations.json`, `data/pattern_recs_for_uc.json`
   - Status: âš ï¸ Incomplete (output files are only 2B)

### Alternative Implementations (Testing/Comparison)
4. **02_generate_patterns_ai_functions.py** â†’ Pattern generation using Databricks AI Functions
   - Purpose: Alternative to REST API approach
   - Status: Tested, not used in final pipeline

5. **02_test_pattern_generation.py** â†’ Unit tests for pattern generation
   - Purpose: Validate pattern quality
   - Status: Testing notebook

6. **03_generate_patterns_rest_api.py** â†’ Pattern generation using REST API endpoints
   - Purpose: Alternative approach to AI Functions
   - Status: Tested, not used in final pipeline

7. **05_rule_based_pairing.py** â†’ Deterministic rule-based pairing fallback
   - Purpose: Backup approach when pattern matching fails
   - Status: Implemented in `OutfitCompatibilityService` instead

### Reference Notebooks
8. **migrate_to_lakebase.ipynb** â†’ Migration guide from fashion_demo to fashion_sota
   - Purpose: Historical reference for schema migration
   - Status: Keep for reference

9. **QUICK_SETUP_64_WORKERS.md** â†’ Setup documentation for parallel processing
   - Purpose: Documentation for scaling pattern generation
   - Status: Keep as documentation

---

## ğŸ”¬ Research/Exploratory Notebooks (Archive Candidates)

These were exploratory research, superseded approaches, or experiments:

### Lookbook-Based Approach (Superseded)
- **generate_outfit_pairs_from_lookbook.py**
  - Original approach: Extract pairings from 29 lookbook images
  - Result: Only 2.4% coverage (1,086 products)
  - Superseded by: Pattern-based approach
  - â†’ **Archive**

### External Dataset Research (Not Used)
- **deepfashion2_complete_the_look.py**
  - Research on DeepFashion2 dataset for outfit completion
  - Not integrated into production
  - â†’ **Archive**

- **complementarity.py**
  - Research on complementarity metrics for outfit pairing
  - Not integrated into production
  - â†’ **Archive**

### Multimodal Model Experiments (Not Used)
- **latent_feature_extraction_qwen.py**
  - Experiment with Qwen multimodal model for feature extraction
  - Not integrated into production
  - â†’ **Archive**

### Attribute Extraction Pipeline (Not Used)
- **smolvlm_batch_attribute_extraction.py** (v1)
- **smolvlm_batch_attribute_extraction_endpoint.py** (v2 - endpoint version)
- **smolvlm_batch_attribute_extraction_fixed.py** (v3 - bug fixes)
- **smolvlm_batch_attribute_extraction_optimized.py** (v4 - optimized)
  - SmolVLM experiments for extracting product attributes
  - Results: Not integrated into production workflow
  - â†’ **Archive all 4 versions**

### Unknown/Untitled
- **RepEng.ipynb**
  - Unknown purpose (likely exploratory)
  - â†’ **Archive**

---

## ğŸ“Š Summary

| Category | Count | Action |
|----------|-------|--------|
| **Production Pipeline** | 3 | Keep & Rename (01, 02, 04) |
| **Alternative Implementations** | 4 | Keep (useful for testing) |
| **Reference** | 2 | Keep (migration + docs) |
| **Research/Exploratory** | 10 | Archive |
| **Total** | 19 | |

---

## âœ¨ Proposed Reorganization

### Keep in `notebooks/` (Rename for clarity)
```
notebooks/
â”œâ”€â”€ production/
â”‚   â”œâ”€â”€ 01_select_anchor_products.py          (KEEP - Step 1)
â”‚   â”œâ”€â”€ 02_generate_outfit_patterns.py        (KEEP - Step 2)
â”‚   â””â”€â”€ 03_apply_patterns_to_catalog.py       (RENAME from 04_batch_apply_patterns.py)
â”‚
â”œâ”€â”€ alternative_approaches/
â”‚   â”œâ”€â”€ 02a_generate_patterns_ai_functions.py (RENAME - AI Functions version)
â”‚   â”œâ”€â”€ 02b_generate_patterns_rest_api.py     (RENAME - REST API version)
â”‚   â”œâ”€â”€ 02_test_pattern_generation.py         (KEEP - Testing)
â”‚   â””â”€â”€ 05_rule_based_pairing.py              (KEEP - Fallback approach)
â”‚
â”œâ”€â”€ reference/
â”‚   â”œâ”€â”€ migrate_to_lakebase.ipynb             (KEEP - Migration guide)
â”‚   â””â”€â”€ QUICK_SETUP_64_WORKERS.md             (KEEP - Setup docs)
â”‚
â””â”€â”€ README.md                                  (NEW - This inventory)
```

### Archive to `archive/notebooks_research/`
```
archive/notebooks_research/
â”œâ”€â”€ lookbook_approach/
â”‚   â””â”€â”€ generate_outfit_pairs_from_lookbook.py
â”‚
â”œâ”€â”€ external_datasets/
â”‚   â”œâ”€â”€ deepfashion2_complete_the_look.py
â”‚   â””â”€â”€ complementarity.py
â”‚
â”œâ”€â”€ multimodal_experiments/
â”‚   â””â”€â”€ latent_feature_extraction_qwen.py
â”‚
â”œâ”€â”€ smolvlm_attribute_extraction/
â”‚   â”œâ”€â”€ smolvlm_batch_attribute_extraction.py
â”‚   â”œâ”€â”€ smolvlm_batch_attribute_extraction_endpoint.py
â”‚   â”œâ”€â”€ smolvlm_batch_attribute_extraction_fixed.py
â”‚   â””â”€â”€ smolvlm_batch_attribute_extraction_optimized.py
â”‚
â””â”€â”€ misc/
    â””â”€â”€ RepEng.ipynb
```

---

## ğŸ” Data Flow Verification

**Current Data Files** (what's actually being used):
- âœ… `data/anchor_products.json` (72KB) - 200 anchor products
- âœ… `data/outfit_patterns.json` (153KB) - Patterns for anchors
- âš ï¸ `data/pattern_based_recommendations.json` (2B) - INCOMPLETE
- âš ï¸ `data/pattern_recs_for_uc.json` (2B) - INCOMPLETE

**Issue**: Step 3 (04_batch_apply_patterns.py) appears incomplete. Output files are only 2 bytes.

**Recommendation**:
1. Review `04_batch_apply_patterns.py` for errors
2. Re-run to complete the pattern application
3. Verify output files are populated

---

## ğŸ¬ Next Actions

1. **Immediate**: Archive 10 research notebooks
2. **Soon**: Reorganize remaining 9 notebooks into subdirectories
3. **Fix**: Complete pattern application pipeline (Step 3)
4. **Document**: Create README.md in notebooks/ with usage instructions

---

_Analysis Date: 2026-01-08_
_Generated during codebase cleanup initiative_
