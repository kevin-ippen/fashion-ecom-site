# Databricks notebook source
# MAGIC %md
# MAGIC # Create Improved Personas with Better Synthetic Embeddings
# MAGIC
# MAGIC **Objective**: Reduce from 8 personas to 5 high-quality personas with properly aligned embeddings
# MAGIC
# MAGIC **Approach**:
# MAGIC 1. Select 5 personas with distinct styles
# MAGIC 2. For each persona, sample products that match their style
# MAGIC 3. Generate synthetic user embeddings by averaging product embeddings
# MAGIC 4. Filter out Indian garments (Saree, Kurta, etc.)
# MAGIC 5. Ensure luxury persona has diverse products (not just footwear)
# MAGIC
# MAGIC **New Personas**:
# MAGIC - Luxury: High-end fashion enthusiast ($2000+ avg)
# MAGIC - Urban Casual: Modern everyday style ($800-1500)
# MAGIC - Athletic: Active lifestyle wear ($500-1200)
# MAGIC - Budget Savvy: Quality on a budget ($300-800)
# MAGIC - Professional: Business and formal wear ($1000-2000)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Setup

# COMMAND ----------

import pyspark.sql.functions as F
from pyspark.sql.types import ArrayType, DoubleType, FloatType
import numpy as np
from typing import List, Dict
import json

# Configuration
CATALOG = "fashion_sota"
SCHEMA = "default"
PRODUCTS_TABLE = f"{CATALOG}.products_lakebase"
EMBEDDINGS_TABLE = f"{CATALOG}.product_embeddings_multimodal"
USERS_TABLE = f"{CATALOG}.users_lakebase"

# Exclude Indian garments
EXCLUDED_SUBCATEGORIES = [
    "Saree", "Kurta", "Kurtas", "Dupatta", "Churidar", "Salwar",
    "Lehenga Choli", "Kameez", "Dhoti", "Patiala", "Kurta Sets",
    "Sarees", "Salwar and Dupatta", "Lehenga"
]

print(f"ðŸ“Š Working with catalog: {CATALOG}")
print(f"ðŸš« Excluding subcategories: {EXCLUDED_SUBCATEGORIES}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Persona Definitions

# COMMAND ----------

# Define 5 high-quality personas with specific product preferences
PERSONAS = {
    "luxury": {
        "user_id": "user_luxury_001",
        "style_profile": "luxury",
        "description": "Luxury Fashion Enthusiast",
        "price_range": (2000, 100000),
        "avg_price": 3500,
        "preferred_categories": ["Apparel", "Accessories", "Footwear"],
        "category_weights": {"Apparel": 0.5, "Accessories": 0.3, "Footwear": 0.2},
        "color_prefs": ["Black", "White", "Grey", "Navy Blue", "Beige"],
        "sub_category_preferences": [
            "Formal Shoes", "Heels", "Watches", "Handbags", "Jackets",
            "Blazers", "Dresses", "Shirts", "Trousers"
        ],
        "sample_size": 100
    },
    "urban_casual": {
        "user_id": "user_casual_002",
        "style_profile": "urban_casual",
        "description": "Urban Casual Style",
        "price_range": (800, 1500),
        "avg_price": 1100,
        "preferred_categories": ["Apparel", "Footwear", "Accessories"],
        "category_weights": {"Apparel": 0.6, "Footwear": 0.25, "Accessories": 0.15},
        "color_prefs": ["Blue", "Black", "White", "Grey", "Olive"],
        "sub_category_preferences": [
            "Casual Shoes", "Sneakers", "Tshirts", "Jeans", "Shirts",
            "Sweatshirts", "Backpacks", "Sunglasses"
        ],
        "sample_size": 100
    },
    "athletic": {
        "user_id": "user_athletic_003",
        "style_profile": "athletic",
        "description": "Athletic Lifestyle",
        "price_range": (500, 1200),
        "avg_price": 850,
        "preferred_categories": ["Apparel", "Footwear"],
        "category_weights": {"Apparel": 0.55, "Footwear": 0.45},
        "color_prefs": ["Black", "Grey", "Blue", "Red", "White"],
        "sub_category_preferences": [
            "Sports Shoes", "Track Pants", "Tshirts", "Shorts",
            "Sweatshirts", "Tracksuits", "Sports Sandals"
        ],
        "sample_size": 100
    },
    "budget_savvy": {
        "user_id": "user_budget_004",
        "style_profile": "budget_savvy",
        "description": "Budget-Conscious Shopper",
        "price_range": (300, 800),
        "avg_price": 550,
        "preferred_categories": ["Apparel", "Footwear", "Accessories"],
        "category_weights": {"Apparel": 0.5, "Footwear": 0.3, "Accessories": 0.2},
        "color_prefs": ["Blue", "Black", "White", "Grey", "Red"],
        "sub_category_preferences": [
            "Tshirts", "Casual Shoes", "Shirts", "Jeans", "Flip Flops",
            "Sandals", "Socks", "Belts", "Wallets"
        ],
        "sample_size": 100
    },
    "professional": {
        "user_id": "user_professional_005",
        "style_profile": "professional",
        "description": "Business Professional",
        "price_range": (1000, 2000),
        "avg_price": 1500,
        "preferred_categories": ["Apparel", "Accessories", "Footwear"],
        "category_weights": {"Apparel": 0.5, "Accessories": 0.3, "Footwear": 0.2},
        "color_prefs": ["Black", "Navy Blue", "Grey", "White", "Brown"],
        "sub_category_preferences": [
            "Formal Shoes", "Shirts", "Trousers", "Blazers", "Watches",
            "Ties", "Belts", "Wallets", "Dress"
        ],
        "sample_size": 100
    }
}

print(f"âœ… Defined {len(PERSONAS)} personas:")
for name, config in PERSONAS.items():
    print(f"  - {name}: {config['description']} (${config['avg_price']} avg)")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Load Product Data

# COMMAND ----------

# Load products (excluding Indian garments)
products_df = spark.table(PRODUCTS_TABLE) \
    .filter(~F.col("sub_category").isin(EXCLUDED_SUBCATEGORIES)) \
    .filter(F.col("price") > 0)

print(f"ðŸ“¦ Total products (excluding Indian garments): {products_df.count():,}")

# Join with embeddings
products_with_embeddings = products_df.join(
    spark.table(EMBEDDINGS_TABLE).select("product_id", "hybrid_embedding"),
    on="product_id",
    how="inner"
).filter(F.col("hybrid_embedding").isNotNull())

print(f"ðŸ“Š Products with embeddings: {products_with_embeddings.count():,}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Generate Synthetic User Embeddings
# MAGIC
# MAGIC For each persona:
# MAGIC 1. Sample products matching their preferences
# MAGIC 2. Extract product embeddings
# MAGIC 3. Average embeddings to create user embedding
# MAGIC 4. Normalize to unit L2 norm

# COMMAND ----------

def sample_products_for_persona(persona_config: Dict) -> List[int]:
    """
    Sample products that match persona preferences

    Returns list of product_ids
    """
    min_price, max_price = persona_config["price_range"]
    preferred_cats = persona_config["preferred_categories"]
    sub_cat_prefs = persona_config["sub_category_preferences"]
    sample_size = persona_config["sample_size"]

    # Filter by price and categories
    filtered = products_with_embeddings.filter(
        (F.col("price") >= min_price) &
        (F.col("price") <= max_price) &
        (F.col("master_category").isin(preferred_cats))
    )

    # Boost products in preferred sub-categories
    preferred_products = filtered.filter(F.col("sub_category").isin(sub_cat_prefs))
    other_products = filtered.filter(~F.col("sub_category").isin(sub_cat_prefs))

    # Sample: 70% from preferred sub-categories, 30% from others
    preferred_sample_size = int(sample_size * 0.7)
    other_sample_size = sample_size - preferred_sample_size

    preferred_sample = preferred_products.limit(preferred_sample_size * 2) \
        .orderBy(F.rand(seed=42)) \
        .limit(preferred_sample_size)

    other_sample = other_products.limit(other_sample_size * 2) \
        .orderBy(F.rand(seed=43)) \
        .limit(other_sample_size)

    sampled = preferred_sample.union(other_sample)

    # Get product IDs
    product_ids = [row.product_id for row in sampled.select("product_id").collect()]

    return product_ids


def create_user_embedding_from_products(product_ids: List[int]) -> np.ndarray:
    """
    Create user embedding by averaging product embeddings

    Returns normalized 512-dim embedding
    """
    # Get embeddings for sampled products
    embeddings_df = spark.table(EMBEDDINGS_TABLE) \
        .filter(F.col("product_id").isin(product_ids)) \
        .select("product_id", "hybrid_embedding") \
        .collect()

    # Convert to numpy arrays
    embeddings = []
    for row in embeddings_df:
        emb = np.array(row.hybrid_embedding, dtype=np.float32)
        embeddings.append(emb)

    if not embeddings:
        raise ValueError("No embeddings found for sampled products")

    # Average embeddings
    user_embedding = np.mean(embeddings, axis=0)

    # Normalize to unit L2 norm (critical for cosine similarity!)
    norm = np.linalg.norm(user_embedding)
    if norm > 0:
        user_embedding = user_embedding / norm

    return user_embedding


# Generate embeddings for all personas
persona_embeddings = {}

for persona_name, persona_config in PERSONAS.items():
    print(f"\n{'='*80}")
    print(f"Generating embedding for {persona_name.upper()}")
    print(f"{'='*80}")

    # Sample products
    product_ids = sample_products_for_persona(persona_config)
    print(f"  âœ“ Sampled {len(product_ids)} products")

    # Show sample products
    sample_products = products_with_embeddings \
        .filter(F.col("product_id").isin(product_ids[:10])) \
        .select("product_id", "product_display_name", "master_category", "sub_category", "price") \
        .collect()

    print(f"\n  Sample products:")
    for p in sample_products:
        print(f"    - {p.product_display_name} ({p.sub_category}, ${p.price:.0f})")

    # Create embedding
    user_embedding = create_user_embedding_from_products(product_ids)
    persona_embeddings[persona_name] = {
        "user_id": persona_config["user_id"],
        "embedding": user_embedding,
        "sampled_products": product_ids
    }

    # Validate
    norm = np.linalg.norm(user_embedding)
    print(f"\n  âœ“ Generated {len(user_embedding)}-dim embedding (L2 norm = {norm:.6f})")
    print(f"  âœ“ Embedding stats: min={user_embedding.min():.4f}, max={user_embedding.max():.4f}, mean={user_embedding.mean():.4f}")

print(f"\n{'='*80}")
print(f"âœ… Generated embeddings for {len(persona_embeddings)} personas")
print(f"{'='*80}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Create/Update User Records

# COMMAND ----------

from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType, IntegerType, MapType

# Prepare user records
user_records = []

for persona_name, persona_config in PERSONAS.items():
    embedding_data = persona_embeddings[persona_name]
    embedding = embedding_data["embedding"].tolist()

    # Build color preferences (equal weights for demo)
    color_prefs = {color: 1.0 / len(persona_config["color_prefs"])
                   for color in persona_config["color_prefs"]}

    # Build brand preferences (empty for now)
    brand_prefs = {}

    user_record = {
        "user_id": persona_config["user_id"],
        "style_profile": persona_config["style_profile"],
        "preferred_categories": persona_config["preferred_categories"],
        "color_prefs": color_prefs,
        "brand_prefs": brand_prefs,
        "min_price": float(persona_config["price_range"][0]),
        "max_price": float(persona_config["price_range"][1]),
        "avg_price": float(persona_config["avg_price"]),
        "p25_price": float(persona_config["avg_price"] * 0.7),
        "p50_price": float(persona_config["avg_price"]),
        "p75_price": float(persona_config["avg_price"] * 1.3),
        "p90_price": float(persona_config["price_range"][1]),
        "num_interactions": 1000,  # Mock value
        "user_embedding": embedding
    }

    user_records.append(user_record)

# Create DataFrame
schema = StructType([
    StructField("user_id", StringType(), False),
    StructField("style_profile", StringType(), True),
    StructField("preferred_categories", ArrayType(StringType()), True),
    StructField("color_prefs", MapType(StringType(), FloatType()), True),
    StructField("brand_prefs", MapType(StringType(), FloatType()), True),
    StructField("min_price", FloatType(), True),
    StructField("max_price", FloatType(), True),
    StructField("avg_price", FloatType(), True),
    StructField("p25_price", FloatType(), True),
    StructField("p50_price", FloatType(), True),
    StructField("p75_price", FloatType(), True),
    StructField("p90_price", FloatType(), True),
    StructField("num_interactions", IntegerType(), True),
    StructField("user_embedding", ArrayType(FloatType()), True)
])

users_df = spark.createDataFrame(user_records, schema=schema)

print(f"âœ… Created DataFrame with {users_df.count()} user records")
users_df.show(truncate=False)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Write to Users Table
# MAGIC
# MAGIC **Note**: This will UPSERT the 5 new persona users into the existing users table

# COMMAND ----------

# Write using Delta merge (upsert)
from delta.tables import DeltaTable

# Check if table exists
if spark.catalog.tableExists(USERS_TABLE):
    print(f"ðŸ“Š Table {USERS_TABLE} exists, performing MERGE (upsert)...")

    delta_table = DeltaTable.forName(spark, USERS_TABLE)

    delta_table.alias("target").merge(
        users_df.alias("source"),
        "target.user_id = source.user_id"
    ).whenMatchedUpdateAll() \
     .whenNotMatchedInsertAll() \
     .execute()

    print(f"âœ… Merged {len(user_records)} personas into {USERS_TABLE}")
else:
    print(f"ðŸ“Š Table {USERS_TABLE} does not exist, creating...")
    users_df.write.format("delta").mode("overwrite").saveAsTable(USERS_TABLE)
    print(f"âœ… Created {USERS_TABLE} with {len(user_records)} personas")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Verify Results

# COMMAND ----------

# Verify the personas were created/updated
result_df = spark.table(USERS_TABLE) \
    .filter(F.col("user_id").isin([p["user_id"] for p in PERSONAS.values()]))

print(f"\n{'='*80}")
print(f"VERIFICATION: New Personas in {USERS_TABLE}")
print(f"{'='*80}")
result_df.select(
    "user_id",
    "style_profile",
    "preferred_categories",
    "avg_price",
    F.size("user_embedding").alias("embedding_dim")
).show(truncate=False)

# Verify embeddings are normalized
print(f"\n{'='*80}")
print(f"EMBEDDING VALIDATION")
print(f"{'='*80}")

for persona_name, persona_config in PERSONAS.items():
    user_id = persona_config["user_id"]
    row = result_df.filter(F.col("user_id") == user_id).select("user_embedding").first()

    if row and row.user_embedding:
        embedding = np.array(row.user_embedding, dtype=np.float32)
        norm = np.linalg.norm(embedding)
        print(f"{persona_name} ({user_id}):")
        print(f"  - Dimension: {len(embedding)}")
        print(f"  - L2 Norm: {norm:.6f} {'âœ… NORMALIZED' if abs(norm - 1.0) < 0.01 else 'âŒ NOT NORMALIZED'}")
        print(f"  - Range: [{embedding.min():.4f}, {embedding.max():.4f}]")
        print()

# COMMAND ----------

# MAGIC %md
# MAGIC ## Save Persona Mapping
# MAGIC
# MAGIC Export new persona IDs for frontend configuration

# COMMAND ----------

persona_mapping = {
    persona_name: {
        "user_id": config["user_id"],
        "display_name": config["description"],
        "style_profile": config["style_profile"],
        "avg_price": config["avg_price"],
        "price_range": config["price_range"]
    }
    for persona_name, config in PERSONAS.items()
}

# Save to DBFS for easy access
mapping_json = json.dumps(persona_mapping, indent=2)
dbutils.fs.put(
    f"/Volumes/{CATALOG}/default/config/new_persona_mapping.json",
    mapping_json,
    overwrite=True
)

print("âœ… Saved persona mapping to:")
print(f"   /Volumes/{CATALOG}/default/config/new_persona_mapping.json")
print(f"\nMapping:")
print(mapping_json)

# COMMAND ----------

# MAGIC %md
# MAGIC ## Summary
# MAGIC
# MAGIC âœ… Created 5 high-quality personas with properly aligned embeddings:
# MAGIC
# MAGIC 1. **Luxury**: High-end fashion ($2000+ avg) - diverse products (not just footwear!)
# MAGIC 2. **Urban Casual**: Modern everyday style ($800-1500)
# MAGIC 3. **Athletic**: Active lifestyle wear ($500-1200)
# MAGIC 4. **Budget Savvy**: Quality on a budget ($300-800)
# MAGIC 5. **Professional**: Business and formal wear ($1000-2000)
# MAGIC
# MAGIC **Key Improvements**:
# MAGIC - âœ… Embeddings generated from actual product embeddings (perfect alignment)
# MAGIC - âœ… Embeddings normalized to L2 norm = 1.0 (matches product embeddings)
# MAGIC - âœ… Indian garments (Saree, Kurta, etc.) excluded from sampling
# MAGIC - âœ… Luxury persona has balanced category mix (50% Apparel, 30% Accessories, 20% Footwear)
# MAGIC - âœ… Each persona has distinct price range and style preferences
# MAGIC
# MAGIC **Next Steps**:
# MAGIC 1. Update frontend `routes/v1/users.py` with new CURATED_PERSONA_IDS
# MAGIC 2. Add Indian garment filters to recommendation service
# MAGIC 3. Test recommendations for each persona
# MAGIC 4. Deploy to production
